{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backgroundFinder(video, upperlim, retframe):\n",
    "    \"\"\"\n",
    "    video: relative pathway to the video to load in.\n",
    "    upperlim: when to stop running the video, default = 1000 frames.\n",
    "    while recursiveBStrack should be able to handle slight\n",
    "    movements to the arena, it is still best to choose a background that\n",
    "    the majority of the video will live in.\n",
    "    \"\"\"\n",
    "    video_capture = cv2.VideoCapture(video)\n",
    "    \n",
    "    frame_counter = 0\n",
    "\n",
    "    # Loop to read and display each frame\n",
    "    while frame_counter < upperlim:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break  # Break the loop when no frames left\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Increment frame counter\n",
    "        frame_counter += 1\n",
    "\n",
    "        # Display frame counter\n",
    "        cv2.putText(frame, f'Frame: {frame_counter}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close all windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video)\n",
    "\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(retframe):\n",
    "        frames.append(video_capture.read()[1])\n",
    "\n",
    "    video_capture.release()\n",
    "\n",
    "    background = np.array(frames[-1])\n",
    "\n",
    "    return background\n",
    "\n",
    "\n",
    "def RecursiveeBSTracker(video, initbackground, centroid_size, crop = None, start = 0):\n",
    "    \"\"\"    \n",
    "    video: a relative pathway to the video to process\n",
    "    initbackground: the cv2 image of the background, obtained \n",
    "    using the return of the backgroundFinder function\n",
    "    crop: a list storing the pixel index for the top, bottom, left, \n",
    "    and right bounds of the arena (all else will be cropped)\n",
    "    centroid_size: determines the size of the box which will encapsulate\n",
    "    the center mass of brightness in the current frame. background will\n",
    "    be updated with everything outside of this box. ** this parameter\n",
    "    should scale with the pixel-size of your animal! **\n",
    "    \"\"\"\n",
    "    video_capture = cv2.VideoCapture(video)\n",
    "\n",
    "    backcropped = initbackground\n",
    "\n",
    "    if crop:\n",
    "        backcropped = initbackground[crop[0]:crop[1],crop[2]:crop[3]]\n",
    "\n",
    "    subtract_video = []\n",
    "    signed_background = backcropped.astype(np.int16)\n",
    "\n",
    "    frameCounter = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break  # Break the loop when no frames left\n",
    "        \n",
    "        if frameCounter < start:\n",
    "            continue\n",
    "\n",
    "        if crop:\n",
    "    \n",
    "            frame = frame[crop[0]:crop[1],crop[2]:crop[3]]  # 330, 250\n",
    "\n",
    "        #Condition for when to update background\n",
    "\n",
    "        # Convert each element in the array to an integer\n",
    "        if (frameCounter%5==0):\n",
    "            subtract_video.append(np.clip(np.clip(np.abs(frame.astype(np.int16) - signed_background)-20, 0, None)*2, 0, 255).astype(np.uint8))\n",
    "        \n",
    "        if(frameCounter%200==0 and frameCounter>1000):\n",
    "            gray_subtract_last = cv2.cvtColor(subtract_video[-1], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # this centroid pair will onl;y be used for updating background\n",
    "            moments = cv2.moments(gray_subtract_last)\n",
    "            if moments['m00'] != 0:\n",
    "                centroid_x = int(moments['m10'] / moments['m00'])\n",
    "                centroid_y = int(moments['m01'] / moments['m00'])\n",
    "            else:\n",
    "                centroid_x, centroid_y = None, None  # Handle the case of no bright regions\n",
    "\n",
    "            leftBound = np.clip(centroid_x - centroid_size, 0, None)\n",
    "            rightBound = np.clip(centroid_x + centroid_size, None, 249)\n",
    "            bottomBound = np.clip(centroid_y + centroid_size, None, 329)\n",
    "            topBound = np.clip(centroid_y - centroid_size, 0, None)\n",
    "\n",
    "\n",
    "            #cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)  # Draw a red circle\n",
    "\n",
    "            #cv2.rectangle(frame, (leftBound,topBound), (rightBound,bottomBound), (0, 255, 0), 3)  # Green square with thickness of 3\n",
    "\n",
    "\n",
    "            # take everything in grayscale_frame that is outside of left, right, top, bottom bounds and update signed_background\n",
    "\n",
    "            for x in range(0,250):\n",
    "                for y in range(0,330):\n",
    "                    # if we are outside\n",
    "                    if not ((x>leftBound) and (x<rightBound) and (y<bottomBound) and (y>topBound) ):\n",
    "\n",
    "                        signed_background[y][x] = frame[y][x]\n",
    "\n",
    "        \n",
    "        frameCounter = frameCounter+1\n",
    "\n",
    "    return subtract_video\n",
    "\n",
    "def watch(processedVid, tracker, trackerSize, trackerColor = (0,0,255)):\n",
    "    \"\"\"\n",
    "    processedVid: output of RecursiveBSTracker\n",
    "    tracker: bool, do you want a center of mass tracker? \n",
    "    (you should select no if using this for preprocessing e.g.,\n",
    "    for use in SLEAP or some similar deep learning program)\n",
    "    trackerColor: RGB value for tracker\n",
    "    trackerSize: marker size for tracker circle\n",
    "    \"\"\"\n",
    "\n",
    "    subtract_vid = processedVid\n",
    "\n",
    "    if tracker:\n",
    "        gray_subtract = [cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in processedVid] \n",
    "\n",
    "        for i in range(len(gray_subtract)):\n",
    "\n",
    "            moments = cv2.moments(gray_subtract[i])\n",
    "            if moments['m00'] != 0:\n",
    "                centroid_x = int(moments['m10'] / moments['m00'])\n",
    "                centroid_y = int(moments['m01'] / moments['m00'])\n",
    "            else:\n",
    "                centroid_x, centroid_y = None, None  # Handle the case of no bright regions\n",
    "\n",
    "            cv2.circle(subtract_vid[i], (centroid_x, centroid_y), trackerSize, trackerColor, -1)  # Draw a red circle\n",
    "\n",
    "\n",
    "\n",
    "    for frame in subtract_vid:\n",
    "        cv2.imshow('Modified Frame', frame) # 330 x 250\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "video_capture = cv2.VideoCapture('./2_2023-07-31_18-14-52_F2_BL1_EdgeGravel.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "relativeCray = './2_2023-07-31_18-14-52_F2_BL1_EdgeGravel.avi'\n",
    "relCrayCrop = [120,450,170,420]\n",
    "relCrayCentrSz = 60\n",
    "initbackground = backgroundFinder(relativeCray,10, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedVideo = RecursiveeBSTracker(relativeCray, initbackground, relCrayCentrSz, relCrayCrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessedVideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m190\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m170\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 158\u001b[0m, in \u001b[0;36mwatch\u001b[1;34m(processedVid, tracker, trackerSize, trackerColor)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m subtract_vid:\n\u001b[0;32m    157\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModified Frame\u001b[39m\u001b[38;5;124m'\u001b[39m, frame) \u001b[38;5;66;03m# 330 x 250\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    159\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "watch(processedVideo, True, 2, (190,170,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "relativeRat = 'R45_Male_Water_Round_3_Camera_3_Separate_2023-12-18.avi'\n",
    "relRatCrop = None\n",
    "relRatCentrSz = 60\n",
    "initbackground = backgroundFinder(relativeRat,10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedVideo = RecursiveeBSTracker(relativeRat, initbackground, relRatCentrSz, start = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch(processedVideo, True, 2, (190,170,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for i in range(250):\n",
    "    frames.append(video_capture.read()[1])\n",
    "\n",
    "video_capture.release()\n",
    "\n",
    "background = np.array(frames[-1])\n",
    "\n",
    "#print(background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 75  78  76]\n",
      " [ 76  79  77]\n",
      " [ 71  74  72]\n",
      " [ 72  75  73]\n",
      " [ 73  76  74]\n",
      " [ 64  67  65]\n",
      " [192 186 181]\n",
      " [255 250 245]\n",
      " [245 254 248]\n",
      " [251 255 254]]\n",
      "[[73 76 74]\n",
      " [78 81 79]\n",
      " [76 79 77]\n",
      " [72 75 73]\n",
      " [70 73 71]\n",
      " [70 73 71]\n",
      " [77 71 66]\n",
      " [73 67 62]\n",
      " [53 62 56]\n",
      " [57 66 60]]\n",
      "[[94 97 95]\n",
      " [75 78 76]\n",
      " [71 74 72]\n",
      " [58 61 59]\n",
      " [72 75 73]\n",
      " [59 62 60]\n",
      " [64 71 59]\n",
      " [55 62 50]\n",
      " [69 63 66]\n",
      " [73 67 70]]\n",
      "[[84 87 85]\n",
      " [78 81 79]\n",
      " [82 85 83]\n",
      " [85 88 86]\n",
      " [72 75 73]\n",
      " [69 72 70]\n",
      " [69 76 64]\n",
      " [68 75 63]\n",
      " [78 72 75]\n",
      " [71 65 68]]\n",
      "[[86 89 87]\n",
      " [88 91 89]\n",
      " [82 85 83]\n",
      " [84 87 85]\n",
      " [69 72 70]\n",
      " [66 69 67]\n",
      " [85 77 67]\n",
      " [83 75 65]\n",
      " [54 67 75]\n",
      " [49 62 70]]\n",
      "[[91 94 92]\n",
      " [79 82 80]\n",
      " [86 89 87]\n",
      " [73 76 74]\n",
      " [69 72 70]\n",
      " [58 61 59]\n",
      " [74 66 56]\n",
      " [83 75 65]\n",
      " [57 70 78]\n",
      " [49 62 70]]\n",
      "[[86 89 87]\n",
      " [83 86 84]\n",
      " [78 81 79]\n",
      " [75 78 76]\n",
      " [71 74 72]\n",
      " [70 73 71]\n",
      " [66 69 67]\n",
      " [62 65 63]\n",
      " [59 62 60]\n",
      " [57 60 58]]\n",
      "[[85 88 86]\n",
      " [80 83 81]\n",
      " [77 80 78]\n",
      " [72 75 73]\n",
      " [70 73 71]\n",
      " [68 71 69]\n",
      " [65 68 66]\n",
      " [62 65 63]\n",
      " [59 62 60]\n",
      " [57 60 58]]\n",
      "[[83 86 84]\n",
      " [78 81 79]\n",
      " [75 78 76]\n",
      " [70 73 71]\n",
      " [68 71 69]\n",
      " [65 68 66]\n",
      " [64 67 65]\n",
      " [62 65 63]\n",
      " [59 62 60]\n",
      " [57 60 58]]\n",
      "[[80 83 81]\n",
      " [77 80 78]\n",
      " [72 75 73]\n",
      " [69 72 70]\n",
      " [65 68 66]\n",
      " [64 67 65]\n",
      " [63 66 64]\n",
      " [62 65 63]\n",
      " [59 62 60]\n",
      " [57 60 58]]\n"
     ]
    }
   ],
   "source": [
    "[print(background[10:20][i][10:20]) for i in range(10)]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for i in range(1000):\n",
    "    frames.append(video_capture.read()[1])\n",
    "\n",
    "video_capture.release()\n",
    "\n",
    "frame1000 = np.array(frames[-1])\n",
    "\n",
    "#print(background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73  77  72]\n",
      " [ 64  68  63]\n",
      " [ 73  77  72]\n",
      " [ 76  80  75]\n",
      " [ 79  83  78]\n",
      " [ 62  66  61]\n",
      " [190 186 182]\n",
      " [255 251 247]\n",
      " [251 253 246]\n",
      " [245 247 240]]\n",
      "[[ 75  78  76]\n",
      " [ 76  79  77]\n",
      " [ 71  74  72]\n",
      " [ 72  75  73]\n",
      " [ 73  76  74]\n",
      " [ 64  67  65]\n",
      " [192 186 181]\n",
      " [255 250 245]\n",
      " [245 254 248]\n",
      " [251 255 254]]\n",
      "[[254 255 252]\n",
      " [244 245 242]\n",
      " [  2   3   0]\n",
      " [  4   5   2]\n",
      " [  6   7   4]\n",
      " [254 255 252]\n",
      " [254   0   1]\n",
      " [  0   1   2]\n",
      " [  6 255 254]\n",
      " [250 248 242]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(frame1000[10:20][i][10:20])\n",
    "\n",
    "    print(background[10:20][i][10:20])\n",
    "    \n",
    "    print(np.abs(np.array(frame1000[10:20][i][10:20]) - np.array(background[10:20][i][10:20])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'backcropped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m background \u001b[38;5;241m=\u001b[39m background[\u001b[38;5;241m120\u001b[39m:\u001b[38;5;241m450\u001b[39m,\u001b[38;5;241m170\u001b[39m:\u001b[38;5;241m420\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModified Frame\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mbackcropped\u001b[49m[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m100\u001b[39m]) \u001b[38;5;66;03m# 330 x 250\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m2225\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      5\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'backcropped' is not defined"
     ]
    }
   ],
   "source": [
    "backcropped = background[120:450,170:420]\n",
    "\n",
    "cv2.imshow('Modified Frame', backcropped) # 330 x 250\n",
    "if cv2.waitKey(2225) & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "video_capture = cv2.VideoCapture('./2_2023-07-31_18-14-52_F2_BL1_EdgeGravel.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "video_capture = cv2.VideoCapture('./2_2023-07-31_18-14-52_F2_BL1_EdgeGravel.avi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "print(type(background[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtract_video = []\n",
    "signed_background = background.astype(np.int16)[120:450,170:420]\n",
    "\n",
    "frameCounter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break  # Break the loop when no frames left\n",
    "\n",
    "    frame = frame[120:450,170:420]  # 330, 250\n",
    "\n",
    "    #Condition for when to update background\n",
    "\n",
    "    # Convert each element in the array to an integer\n",
    "    if (frameCounter%5==0):\n",
    "        subtract_video.append(np.clip(np.clip(np.abs(frame.astype(np.int16) - signed_background)-20, 0, None)*2, 0, 255).astype(np.uint8))\n",
    "    \n",
    "    if(frameCounter%200==0 and frameCounter>1000):\n",
    "        gray_subtract_last = cv2.cvtColor(subtract_video[-1], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # this centroid pair will onl;y be used for updating background\n",
    "        moments = cv2.moments(gray_subtract_last)\n",
    "        if moments['m00'] != 0:\n",
    "            centroid_x = int(moments['m10'] / moments['m00'])\n",
    "            centroid_y = int(moments['m01'] / moments['m00'])\n",
    "        else:\n",
    "            centroid_x, centroid_y = None, None  # Handle the case of no bright regions\n",
    "\n",
    "        leftBound = np.clip(centroid_x - 60, 0, None)\n",
    "        rightBound = np.clip(centroid_x + 60, None, 249)\n",
    "        bottomBound = np.clip(centroid_y + 60, None, 329)\n",
    "        topBound = np.clip(centroid_y - 60, 0, None)\n",
    "\n",
    "\n",
    "        #cv2.circle(frame, (centroid_x, centroid_y), 5, (0, 0, 255), -1)  # Draw a red circle\n",
    "\n",
    "        #cv2.rectangle(frame, (leftBound,topBound), (rightBound,bottomBound), (0, 255, 0), 3)  # Green square with thickness of 3\n",
    "\n",
    "\n",
    "        # take everything in grayscale_frame that is outside of left, right, top, bottom bounds and update signed_background\n",
    "\n",
    "        for x in range(0,250):\n",
    "            for y in range(0,330):\n",
    "                # if we are outside\n",
    "                if not ((x>leftBound) and (x<rightBound) and (y<bottomBound) and (y>topBound) ):\n",
    "\n",
    "                    signed_background[y][x] = frame[y][x]\n",
    "\n",
    "    \n",
    "    frameCounter = frameCounter+1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m subtract_video[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1000\u001b[39m:]:\n\u001b[0;32m      2\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModified Frame\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Close OpenCV windows\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for frame in subtract_video[-1000:]:\n",
    "    cv2.imshow('Modified Frame', frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighed Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtract_vid2 = subtract_video\n",
    "# made grayscale list of frames for computing moment (needs grayscale)\n",
    "gray_subtract = [cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in subtract_video] \n",
    "\n",
    "for i in range(len(gray_subtract)):\n",
    "\n",
    "    moments = cv2.moments(gray_subtract[i])\n",
    "    if moments['m00'] != 0:\n",
    "        centroid_x = int(moments['m10'] / moments['m00'])\n",
    "        centroid_y = int(moments['m01'] / moments['m00'])\n",
    "    else:\n",
    "        centroid_x, centroid_y = None, None  # Handle the case of no bright regions\n",
    "\n",
    "    cv2.circle(subtract_vid2[i], (centroid_x, centroid_y), 5, (0, 0, 255), -1)  # Draw a red circle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video is subtract_video\n",
    "\n",
    "for frame in subtract_vid2[::5]:\n",
    "\n",
    "    cv2.imshow('Modified Frame', frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequent Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "video_capture = cv2.VideoCapture('./2_2023-07-31_18-14-52_F2_BL1_EdgeGravel.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subseq_video = []\n",
    "ret, subframe = video_capture.read()\n",
    "\n",
    "signed_background = background.astype(np.int16)\n",
    "\n",
    "subframe_proper = subframe.astype(np.int16)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop when no frames left\n",
    "\n",
    "    intframe = frame.astype(np.int16)\n",
    "\n",
    "    diff = np.abs(intframe - subframe_proper).astype(np.uint8)\n",
    "    subframe_proper = intframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in subseq_video:\n",
    "    cv2.imshow('Modified Frame', frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_counter = 0\n",
    "\n",
    "# Loop to read and display each frame\n",
    "while frame_counter < 5000:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break  # Break the loop when no frames left\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_counter += 1\n",
    "\n",
    "    # Display frame counter\n",
    "    cv2.putText(frame, f'Frame: {frame_counter}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive figure to select background frame\n",
    "background_image = select_background_frame(video_capture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reset video capture to beginning\n",
    "video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# Read the first frame to determine dimensions\n",
    "ret, frame = video_capture.read()\n",
    "height, width, _ = frame.shape\n",
    "\n",
    "# Create a VideoWriter object to save the processed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter('processed_video.avi', fourcc, 30.0, (width, height))\n",
    "\n",
    "# Process each frame\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break  # Break the loop when no frames left\n",
    "\n",
    "    # Subtract background image from the frame\n",
    "    processed_frame = cv2.absdiff(frame, background_image)\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    output_video.write(processed_frame)\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow('Processed Frame', processed_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  # Break the loop if 'q' is pressed\n",
    "\n",
    "# Release video capture and writer objects\n",
    "video_capture.release()\n",
    "output_video.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
